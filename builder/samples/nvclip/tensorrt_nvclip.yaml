name: nvclip

# top level inference input specification
input:
  - name: "text"
    data_type: TYPE_STRING
    dims: [ -1 ]
    optional: true
  - name: "image"
    data_type: TYPE_CUSTOM_BINARY_BASE64
    dims: [ -1 ]
    optional: true
  - name: "indices"
    data_type: TYPE_STRING
    dims: [ -1 ]
    optional: true

# top level inference output specification
output:
  - name: "embeddings"
    data_type: TYPE_FP32
    dims: [-1, -1]
  - name: "total_tokens"
    data_type: TYPE_INT32
    dims: [ 1 ]
  - name: "num_images"
    data_type: TYPE_INT32
    dims: [ 1 ]

server:
  responders:
    infer:
      operation: create_embedding
      requests:
        # root template for generating input json from the request
        EmbeddingsRequest: >
          {
            "text": [
              {% set text_items = request.input | reject('startswith', 'data:image') | list %}
              {% for item in text_items %}
                {{ item|tojson }}{% if not loop.last %}, {% endif %}
              {% endfor %}
            ],
            "image": [
              {% set image_items = request.input | select('startswith', 'data:image') | map('replace', 'data:image\/[a-zA-Z0-9.+-]+;base64,', '') | list %}
              {% for item in image_items %}
                {{ item|tojson }}{% if not loop.last %}, {% endif %}
              {% endfor %}
            ],
            "indices": [
              {% for item in request.input %}
                "{{ 'image' if item.startswith('data:image') else 'text' }}"{% if not loop.last %}, {% endif %}
              {% endfor %}
            ]
          }
      responses:
        EmbeddingsResponse: >
          {
            "data": [{% for item in response.embeddings %} {"index": {{ loop.index }}, "embedding": {{ item|tojson }}, "object": "embedding"}{% if not loop.last %}, {% endif %}{% endfor %}],
            "usage": { "num_images": {{ response.num_images }}, "prompt_tokens": {{ response.total_tokens }}, "total_tokens": {{ response.total_tokens }}},
            "model": "nvidia/nvclip-vit-h-14",
            "object": "list"
          }

# list of model specifications for inference
models:
  - name: nvclip_clipa_vit_h14_700M_text
    backend: "polygraphy"
    max_batch_size: 64
    input:
      - name: "TEXT"
        data_type: TYPE_INT64
        dims: [-1, -1]
    output:
      - name: "LOGITS_PER_TEXT"
        data_type: TYPE_FP32
        dims: [-1, -1]
    parameters:
      FORCE_CPU_ONLY_INPUT_TENSORS: "no"
      tensorrt_engine: "/opt/nim/.cache/model-repo/nvclip/nvclip_clipa_vit_h14_700M_text.plan"
    preprocessors:
      - kind: "custom"
        name: "openclip-tokenizer"
        input: ["text"]
        output: ["TEXT"]
        config:
          model_path: "/opt/nim/.cache/model-repo/nvclip/"
  - name: nvclip_clipa_vit_h14_700M_vision
    backend: "polygraphy"
    max_batch_size: 64
    input:
      - name: "IMAGE"
        data_type: TYPE_FP32
        dims: [-1, 3, -1, -1]
    output:
      - name: "LOGITS_PER_IMAGE"
        data_type: TYPE_FP32
        dims: [-1, -1]
    parameters:
      FORCE_CPU_ONLY_INPUT_TENSORS: "no"
      tensorrt_engine: "/opt/nim/.cache/model-repo/nvclip/nvclip_clipa_vit_h14_700M_vision.plan"
    preprocessors:
      - kind: "custom"
        name: "nvclip-vision-preprocessor"
        input: ["image"]
        output: ["IMAGE"]
postprocessors:
  - kind: "custom"
    name: "nvclip-postprocessor"
    input: ["LOGITS_PER_TEXT", "LOGITS_PER_IMAGE", "indices"]
    output: ["embeddings", "total_tokens", "num_images"]
# route map
# A route is defined as <tensor source : tensor destination>
# Source and destination should be defined as <MODEL_NAME:["TENSOR_NAME1", "TENSOR_NAME2", ...]>
# Model name is optional, so <:["TENSOR_NAME1", "TENSOR_NAME2", ...]> is valid
# Tensor list is optional too and <my_model:> is valid
routes: {
  ':["text"]': 'nvclip_clipa_vit_h14_700M_text',
  ':["image"]': 'nvclip_clipa_vit_h14_700M_vision',
  ':["indices"]': ':',
  'nvclip_clipa_vit_h14_700M_text:["LOGITS_PER_TEXT"]': ':',
  'nvclip_clipa_vit_h14_700M_vision:["LOGITS_PER_IMAGE"]': ':'
}
