Download the deepstream SDK here https://drive.google.com/file/d/1UPJAKLrXSQOF8fM4Abu-FzqyqSnaLiWV/view?usp=sharing, and copy it to builder/samples/nvsegformer

Prepare the onnx file:

mkdir ~/.cache/nim/model-repo/nv_segformer -p
cp rtdetr_model_latest.quant.onnx ~/.cache/nim/model-repo/nv_segformer

Build the NIM inference flow:

cd builder
python main.py samples/rtdetr/ds_rtdetr.yaml --server-type fastapi -a samples/rtdetr/openapi.yaml -o samples

Build and run the docker image:

docker compose up --build nim-rtdetr

Test the NIM with a client:

cd builder/samples/nvsegformer
python nim_client.py --host 127.0.0.1 --port 8800 --file test.jpg

Know Issues:
- There needs a warm-up for each decoder(PNG/JPG) requiring one test jpg and one test png file being feeded to the NIM respectively