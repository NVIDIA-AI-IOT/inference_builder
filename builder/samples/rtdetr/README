Download the deepstream SDK here https://drive.google.com/file/d/1UPJAKLrXSQOF8fM4Abu-FzqyqSnaLiWV/view?usp=sharing, and copy it to builder/samples/nvsegformer

Prepare the onnx file:

mkdir ~/.cache/nim/model-repo/nv_segformer -p
cp rtdetr_model_latest.quant.onnx ~/.cache/nim/model-repo/nv_segformer

Build the NIM inference flow:

cd builder
python main.py samples/rtdetr/ds_rtdetr.yaml --server-type fastapi -a samples/rtdetr/openapi.yaml -o samples

Build and run the docker image:

cd samples
docker compose up --build nim-rtdetr

Test the NIM with a client:

Install Deepstream SDK to the client environment: \\devrel\share\Deepstream\7.x_ER\20241004_24.10.2_build1\deepstream-7.1_7.1.0-1_amd64.deb

cd builder/samples/nvsegformer
python nim_client.py --host 127.0.0.1 --port 8800 --file test.jpg

Know Issues:
- There needs a warm-up for each decoder(PNG/JPG) requiring one test jpg and one test png file being fed to the NIM respectively