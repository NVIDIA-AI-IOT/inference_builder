model_name: null
encryption_key: tlt_encode
results_dir: /media/local/cls.nvdino_pretrain_0114_final_scale0.8
wandb:
  enable: true
  project: TAO Toolkit
  entity: ''
  tags:
  - training
  - tao-toolkit
  reinit: false
  sync_tensorboard: false
  save_code: false
  name: TAO Toolkit training experiment
model:
  backbone:
    type: vit_large_patch14_dinov2_swiglu
    feat_downsample: false
    pretrained_backbone_path: /tao-pt/mount/pretrained_models/NVDINOv2/ViTL/NV_DINOV2_518.ckpt
    freeze_backbone: true
  head:
    type: TAOLinearClsHead
    binary: false
    num_classes: 1000
    in_channels: 448
    custom_args: null
    loss:
      type: CrossEntropyLoss
      label_smooth_val: 0.0
    topk:
    - 1
    - 5
dataset:
  root_dir: /media/projects.metropolis1/tichou/for_QA/dataset/imagenet2012
  dataset: CLDataset
  num_classes: 1000
  img_size: 224
  batch_size: 1
  workers: 8
  shuffle: true
  augmentation:
    random_flip:
      vflip_probability: 0.0
      hflip_probability: 0.5
      enable: true
    random_rotate:
      rotate_probability: 0.5
      angle_list:
      - 90.0
      - 180.0
      - 270.0
      enable: false
    random_color:
      brightness: 0.4
      contrast: 0.4
      saturation: 0.4
      hue: 0.0
      enable: true
      color_probability: 0.5
    random_erase:
      enable: true
      erase_probability: 0.2
    random_aug:
      enable: true
    with_scale_random_crop:
      scale_range:
      - 1.0
      - 1.2
      enable: false
    with_random_blur: false
    with_random_crop: true
    mean:
    - 0.48145466
    - 0.4578275
    - 0.40821073
    std:
    - 0.26862954
    - 0.26130258
    - 0.27577711
    mixup_cutmix: true
    mixup_alpha: 0.4
  train:
    data_prefix: imagenet/train
  train_nolabel:
    folder_path: ''
  val:
    data_prefix: imagenet/val
  test:
    data_prefix: imagenet/val
train:
  num_gpus: 1
  gpu_ids:
  - 0
  num_nodes: 1
  seed: 1234
  cudnn:
    benchmark: false
    deterministic: true
  num_epochs: 10
  checkpoint_interval: 1
  validation_interval: 1
  resume_training_checkpoint_path: null
  results_dir: null
  optim:
    monitor_name: val_loss
    optim: adamw
    lr: 6.0e-05
    policy: linear
    policy_params:
      step_size: 30
      gamma: 0.1
      milestones:
      - 10
      - 20
    momentum: 0.9
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.999
    skip_names: []
    warmup_epochs: 20
  pretrained_model_path: null
  tensorboard:
    enabled: false
    infrequent_logging_frequency: 2
  enable_ema: false
  ema_decay: 0.998
  clip_grad_norm: 2.0
evaluate:
  num_gpus: 1
  gpu_ids:
  - 0
  num_nodes: 1
  checkpoint: ???
  trt_engine: null
  results_dir: null
  vis_after_n_batches: 16
inference:
  num_gpus: 1
  gpu_ids:
  - 0
  num_nodes: 1
  checkpoint: ???
  trt_engine: null
  results_dir: null
  vis_after_n_batches: 16
export:
  results_dir: ${results_dir}/export
  gpu_id: 0
  checkpoint: /tao-pt/mount/result/for_QA/cls/nvdino_pretrain_0114_final_scale0.8/train/model_epoch_019_step_25040.pth
  onnx_file: ${export.results_dir}/classifier.onnx
  on_cpu: false
  input_channel: 3
  input_width: 224
  input_height: 224
  opset_version: 17
  batch_size: -1
  verbose: false
  format: onnx
  serialize_nvdsinfer: true
gen_trt_engine:
  results_dir: /media/local/cls.nvdino_pretrain_0114_final_scale0.8
  gpu_id: 0
  onnx_file: /media/projects.metropolis1/tichou/for_QA/cls/nvdino_pretrain_0114_final_scale0.8/export/export/classifier.onnx
  trt_engine: /media/local/cls.nvdino_pretrain_0114_final_scale0.8/classifier.onnx.trt
  timing_cache: null
  batch_size: 1
  verbose: false
  tensorrt:
    workspace_size: 1024
    min_batch_size: 1
    opt_batch_size: 1
    max_batch_size: 1
    layers_precision: []
    data_type: FP16
    calibration:
      cal_image_dir: ???
      cal_cache_file: ???
      cal_batch_size: 1
      cal_batches: 1
distill:
  teacher:
    backbone:
      type: fan_small_12_p4_hybrid
      feat_downsample: false
      pretrained_backbone_path: null
      freeze_backbone: false
    head:
      type: TAOLinearClsHead
      binary: false
      num_classes: 1000
      in_channels: 448
      custom_args: null
      loss:
        type: CrossEntropyLoss
        label_smooth_val: 0.0
      topk:
      - 1
  pretrained_teacher_model_path: ???
  bindings: []
  loss_type: KL
  loss_lambda: 0.5
  results_dir: null
