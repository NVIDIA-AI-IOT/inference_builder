openapi: 3.1.0
info:
  title: NVIDIA METROPOLIS INFERENCE SERVICE
  description: NVIDIA METROPOLIS INFERENCE SERVICE
  version: "1.0.0"
  termsOfService: https://nvidia.com/legal/terms-of-use
  contact:
    name: NVIDIA Support
    url: https://help.nvidia.com/
  license:
    name: NVIDIA AI Foundation Models Community License
    url: https://docs.nvidia.com/ai-foundation-models-community-license.pdf
paths:
  /v1/health/ready:
    get:
      tags:
        - "NVIDIA METROPOLIS INFERENCE API"
      summary: Health Ready
      description: Provide your implementation of readiness to know when container
        ready to accept traffic
      operationId: health_ready_v1_health_ready_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema: {}
  /v1/inference:
    post:
      tags:
        - "NVIDIA METROPOLIS INFERENCE API"
      summary: Get the inference result for the provided image input
      description: "Invokes inference for the input images.
        The input image can be Base64 encoded string in the request or it can be
        specified using the file identifier of an uploaded file. "
      operationId: inference
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InferenceRequest'
        required: true
      responses:
        "200":
          description: Invocation is fulfilled.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InferenceResponse'
        "500":
          description: The invocation ended with an error.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Errors'
security:
  - Token: []

components:
  securitySchemes:
    Token:
      type: http
      scheme: bearer
  schemas:
    InferenceRequest:
      additionalProperties: false
      properties:
        input:
          oneOf:
          - type: string
            title: string
            maxLength: 4294967296
            pattern: ^.*$
          - type: array
            items:
              type: string
              pattern: ^.*$
              maxLength: 4294967296
            maxItems: 64
          title: Input
          description: 'The list of images on which you want to perform inference. Images should be in form
          of `data:image/{format};base64,{base64encodedimage}`.Accepted formats are `jpg`, `png` and `jpeg`.'
        text:
          type: array
          items:
            type: array
            items:
              type: string
              maxLength: 256
            maxItems: 10
          title: Text
          description: 'A 2D array of text to be used for the extra prompt on the inference.'
        model:
          type: string
          enum: [nvidia/nvdino-v2, nvidia/c-radio-p3-v3, nvidia/convnext]
          title: Model
          description: ID of the CV model.
          examples:
            - nvidia/nvdino-v2
      type: object
      required:
        - input
        - model
      title: InferenceRequest
      description: List of input images for the inference request.
    InferenceResponse:
      type: object
      properties:
        data:
          items:
            $ref: '#/components/schemas/InferenceResult'
          type: array
          title: Data
          description: The list of inference data generated by the model.
          maxItems: 10
        model:
          type: string
          description: Model used to generate masks.
          example: nvidia/nvdino
          title: Model
        usage:
          $ref: '#/components/schemas/Usage'
          description: Usage statistics for the masks request.
          examples:
          - num_images: 1
      additionalProperties: false
      required:
        - data
        - usage
        - model
      title: InferenceResponse
      description: Response schema for the inference request.

    InferenceResult:
      type: object
      description: Represents detected bounding boxes
      properties:
        index:
          type: integer
          format: int32
          title: Index
          description: The index of the mask in the list of masks.
          minimum: 0
          maximum: 127
        shape:
          type: array
          description: The dimension for understanding the output
          items:
            type: integer
          title: Output Dimensions
          maxItems: 3
        bboxes:
          type: array
          description: The bboxes gives a list of bboxes
          items:
            type: array
            description: |
              bbox format [x1, y1, x2, y2] relative to network input dimension.
              x1, y1 is the top-left corner, x2, y2 is the bottom-right corner.
            items:
              type: number
              format: integer
            maxItems: 4
            minItems: 4
          maxItems: 512
          title: Bounding Boxes
        probs:
          type: array
          description: The probs gives a list of probabilities
          items:
            type: number
            format: float
          maxItems: 512
          title: Probabilities
        labels:
          type: array
          description: The labels of each bounding box
          items:
            type: array
            items:
              type: string
            maxItems: 10
          maxItems: 512
          title: Labels
        masks:
          oneOf:
            - type: array
              description: |
                For instance segmentation. list[list[int]]. Inner list entry is class index. Inner list can be reshaped to 2D mask according to shape field in the response.
              items:
                type: array
                items:
                  type: integer
                  format: uint8
                minItems: 0
                maxItems: 522240 # 544 * 960
              maxItems: 512
            - type: string
              maxLength: 10240
              description: |
                The mask vector as base64 string. The length of the vector depends on the model.
              format: ^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{4}|[A-Za-z0-9+/]{3}=|[A-Za-z0-9+/]{2}==)$
          title: Mask
      required:
        - index
        - mask
      title: SegmentationResult
    Usage:
      properties:
        num_images:
          type: integer
          format: int32
          title: Num Images
          minimum: 0
          maximum: 64
          description: Number of images processed.
      additionalProperties: false
      required:
        - num_images
      title: Usage
    Errors:
      type: object
      properties:
        type:
          type: string
          maxLength: 128
          description: Error type
        title:
          type: string
          maxLength: 128
          description: Error title
        status:
          type: integer
          format: int32
          minimum: 100
          maximum: 999
          description: Error status code
        detail:
          type: string
          maxLength: 1024
          description: Detailed information about the error
        instance:
          type: string
          maxLength: 256
          description: Function instance used to invoke the request
      required:
        - type
        - title
        - status
        - detail
        - instance
      title: Errors
